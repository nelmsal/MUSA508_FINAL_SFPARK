{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7908b7-caa0-4d82-916b-3f03572a72f2",
   "metadata": {},
   "source": [
    "Process for prepping a SafeGraph zip file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d78f05-8cd7-412a-905e-a63c8aaf69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import timedelta\n",
    "import os \n",
    "import numpy as np\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK'\n",
    "os.chdir(path)\n",
    "\n",
    "final_cols = ['trans_id','time','action']\n",
    "pull_cols = ['meter_id', 'day', 'start_time']\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_transactions.parquet'\n",
    "park19 = pd.read_parquet(path, columns=pull_cols)\n",
    "print(len(park19))\n",
    "park19.head()\n",
    "\n",
    "# path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\SFMTA_Parking_Meter_Detailed_Revenue_Transactions.csv'\n",
    "# park19 = pd.read_csv(path)\n",
    "\n",
    "# from get_times_df import get_times_df\n",
    "# park19 = get_times_df()\n",
    "# park19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119a7e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# park19['start_time']    = park19['start_datetime'].dt.hour  + (park19['start_datetime'].dt.minute/60)\n",
    "# park19['end_time']      = park19['end_datetime'].dt.hour + (park19['end_datetime'].dt.minute/60)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "plt.rc('ytick', labelsize=10) \n",
    "x = park19['start_time'].values\n",
    "y = park19['end_time'].values\n",
    "bins = np.linspace(min(x), max(y), 24)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.hist([x, y], bins, label=['Start', 'End'])\n",
    "ax1.set_ylabel(\"Transactions\")\n",
    "ax1.set_xlabel(\"Hour\")\n",
    "\n",
    "ax1.set_title('SF Park Meter Transactions 2019',fontsize=16)\n",
    "\n",
    "import matplotlib as mpl\n",
    "ax1.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\SFMTA_Parking_Meter_Detailed_Revenue_Transactions.csv'\n",
    "park19 = pd.read_csv(\n",
    "    path,\n",
    "    usecols=['TRANSMISSION_DATETIME', 'POST_ID', 'STREET_BLOCK', 'SESSION_START_DT', 'SESSION_END_DT', 'GROSS_PAID_AMT']\n",
    "    )\n",
    "park19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5705d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_starts_ends.parquet'\n",
    "start_ends = pd.read_parquet(path)\n",
    "print(len(start_ends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011de280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(value, decimals):\n",
    "    factor = 1 / (10 ** decimals)\n",
    "    return (value // factor) * factor\n",
    "\n",
    "#bins = [0, 7, 9, 12, 15, 18.00001, 21, 24]\n",
    "bins = [0, 9, 12, 15, 18.00001, 24]\n",
    "labels = [\n",
    "    '12a to {}a'.format(bins[1]),    # 12 - 9?\n",
    "    '{}a to {}p'.format(bins[1], round(bins[2])), # 9 - 12\n",
    "    '{}p to {}p'.format(round(bins[2]), bins[3]-12), # 12 - 3\n",
    "    '{}p to {}p'.format(bins[3]-12, round(bins[4])-12), # 3 - 6\n",
    "    '{}p to 12a'.format(round(bins[4])-12)\n",
    "    ]\n",
    "good_bins = labels[1:-1]\n",
    "\n",
    "def grouper(row, cut_off_time=9, bins=bins, labels=labels, good_bins = good_bins):\n",
    "    hours_actions = row[['time','action']].values.tolist()\n",
    "\n",
    "    use_counter = 0\n",
    "    hour_counter = 0\n",
    "    past_hour = 0\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if action==past_action:\n",
    "            if action == 'start':\n",
    "                pass\n",
    "            elif action == 'end':\n",
    "                pass\n",
    "        elif action!=past_action:\n",
    "            if action == 'end':\n",
    "                if (hour == 18)or(hour == 18.0):\n",
    "                    hour = 17.99999\n",
    "                elif (hour == 12)or(hour == 12.0):\n",
    "                    hour = 11.99999\n",
    "                elif (hour == 15)or(hour == 15.0):\n",
    "                    hour = 14.99999\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    past_hour = 0\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action == 'interval'):\n",
    "            if(past_action == 'start'):\n",
    "                correct_end = hour-.00001\n",
    "                # if (hour == 18)or(hour == 18.0):\n",
    "                #     correct_end = 17.99999\n",
    "                # if (hour == 12)or(hour == 12.0):\n",
    "                #     correct_end = 11.99999\n",
    "                keep.append([correct_end,'end'])\n",
    "                keep.append([hour,'start'])\n",
    "                past_hour = hour\n",
    "                past_action = 'start'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "            \n",
    "    hours_actions = keep\n",
    "    past_hour = 0\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if action==past_action:\n",
    "            if action == 'start':\n",
    "                pass\n",
    "            elif action == 'end':\n",
    "                pass\n",
    "        elif action!=past_action:\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    hours_actions_df = pd.DataFrame(keep, columns=['time','action']).sort_values('time').drop_duplicates()\n",
    "    hours_actions_df = hours_actions_df[hours_actions_df['time']>=cut_off_time]\n",
    "    #hours_actions = hours_actions_df.values.tolist()\n",
    "\n",
    "    hours_actions_df['bins'] = pd.cut(\n",
    "            hours_actions_df['time'], \n",
    "            bins, \n",
    "            labels=labels, \n",
    "            right=False, include_lowest=True\n",
    "            ).astype(str)\n",
    "\n",
    "    hours_actions_df = hours_actions_df[hours_actions_df['bins'].isin(good_bins)]\n",
    "\n",
    "    cols = ['time','count']\n",
    "    def get_times(row):\n",
    "        #start_ends = row[['time', 'action']].values.tolist()\n",
    "        try:\n",
    "            start_ends = row[['time']].values.tolist()\n",
    "            start_ends = np.reshape(start_ends, (round(len(start_ends)/2), 2))\n",
    "\n",
    "            start_ends = [round_down(end-start,3) for start,end in start_ends]\n",
    "            return pd.Series((sum(start_ends), len(start_ends)), index=cols)\n",
    "\n",
    "        except:\n",
    "            print(row[['time', 'action']].values.tolist())\n",
    "            return pd.Series((99, 99), index=cols)\n",
    "    #group_hours_actions_df = hours_actions_df.groupby(['bins', 'action'])['time'].apply(list) #.count()\n",
    "    \n",
    "    group_hours_actions_df = hours_actions_df.groupby('bins').apply(get_times) #.count()\n",
    "\n",
    "    return group_hours_actions_df\n",
    "        \n",
    "\n",
    "base = 150000 - 736\n",
    "page_size = 1000\n",
    "test = start_ends.iloc[base:base+page_size]\n",
    "\n",
    "result = test.groupby('trans_id').apply(grouper)[['time','count']].reset_index() \n",
    "result['trans_bins_id'] = result['trans_id'] + '_' + result['bins']\n",
    "bad_filt = result['time']==99\n",
    "bad_trans_bins = result[bad_filt]['trans_bins_id'].unique()\n",
    "#result = result[~bad_filt]\n",
    "result[['meter_id','day']] = result['trans_id'].str.split('_', expand=True)\n",
    "result['day'] = result['day'].astype(int)\n",
    "result = result.sort_values(['meter_id','day']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_starts_ends.parquet'\n",
    "start_ends = pd.read_parquet(path, columns=['trans_id','time','action'])\n",
    "print(len(start_ends['trans_id'].unique()))\n",
    "# 3607812\n",
    "\n",
    "#####################\n",
    "\n",
    "def round_down(value, decimals):\n",
    "    factor = 1 / (10 ** decimals)\n",
    "    return (value // factor) * factor\n",
    "\n",
    "#bins = [0, 7, 9, 12, 15, 18.00001, 21, 24]\n",
    "bins = [0, 9, 12, 15, 18.00001, 24]\n",
    "labels = [\n",
    "    '12a to {}a'.format(bins[1]),    # 12 - 9?\n",
    "    '{}a to {}p'.format(bins[1], round(bins[2])), # 9 - 12\n",
    "    '{}p to {}p'.format(round(bins[2]), bins[3]-12), # 12 - 3\n",
    "    '{}p to {}p'.format(bins[3]-12, round(bins[4])-12), # 3 - 6\n",
    "    '{}p to 12a'.format(round(bins[4])-12)\n",
    "    ]\n",
    "good_bins = labels[1:-1]\n",
    "\n",
    "#####################\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def grouper(row, cut_off_time=9, bins=bins, labels=labels, good_bins = good_bins):\n",
    "    hours_actions = row[['time','action']].values.tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = counter + 1\n",
    "    if float(counter/10000).is_integer():\n",
    "        print(counter)\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action != 'interval')and(action==past_action):\n",
    "            if action == 'start':\n",
    "                pass\n",
    "            elif action == 'end':\n",
    "                keep.pop()\n",
    "                past_hour = hour\n",
    "                past_action = action\n",
    "                keep.append([hour, action])\n",
    "        elif action!=past_action:\n",
    "            if action == 'end':\n",
    "                if (hour == 18)or(hour == 18.0):\n",
    "                    hour = 17.99999\n",
    "                elif (hour == 12)or(hour == 12.0):\n",
    "                    hour = 11.99999\n",
    "                elif (hour == 15)or(hour == 15.0):\n",
    "                    hour = 14.99999\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action == 'interval'):\n",
    "            if(past_action == 'start'):\n",
    "                correct_end = hour-.00001\n",
    "                # if (hour == 18)or(hour == 18.0):\n",
    "                #     correct_end = 17.99999\n",
    "                # if (hour == 12)or(hour == 12.0):\n",
    "                #     correct_end = 11.99999\n",
    "                keep.append([correct_end,'end'])\n",
    "                keep.append([hour,'start'])\n",
    "                past_action = 'start'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "            \n",
    "    hours_actions = keep\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if action==past_action:\n",
    "            pass\n",
    "        elif action!=past_action:\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    hours_actions_df = pd.DataFrame(keep, columns=['time','action']).sort_values('time').drop_duplicates()\n",
    "    hours_actions_df = hours_actions_df[hours_actions_df['time']>=cut_off_time]\n",
    "    #hours_actions = hours_actions_df.values.tolist()\n",
    "\n",
    "    hours_actions_df['bins'] = pd.cut(\n",
    "            hours_actions_df['time'], \n",
    "            bins, \n",
    "            labels=labels, \n",
    "            right=False, include_lowest=True\n",
    "            ).astype(str)\n",
    "\n",
    "    cols = ['time','count']\n",
    "    def get_times(row):\n",
    "        #start_ends = row[['time', 'action']].values.tolist()\n",
    "        try:\n",
    "            start_ends = row[['time']].values.tolist()\n",
    "            start_ends = np.reshape(start_ends, (round(len(start_ends)/2), 2))\n",
    "\n",
    "            start_ends = [round_down(end-start,3) for start,end in start_ends]\n",
    "            return pd.Series((sum(start_ends), len(start_ends)), index=cols)\n",
    "\n",
    "        except:\n",
    "            #print(row[['time', 'action']].values.tolist())\n",
    "            return pd.Series((99, 99), index=cols)\n",
    "    #group_hours_actions_df = hours_actions_df.groupby(['bins', 'action'])['time'].apply(list) #.count()\n",
    "    \n",
    "    group_hours_actions_df = hours_actions_df[hours_actions_df['bins'].isin(good_bins)].groupby('bins').apply(get_times) #.count()\n",
    "\n",
    "    return group_hours_actions_df\n",
    "\n",
    "start_ends = start_ends[['trans_id','time','action']].sort_values('trans_id')\n",
    "result = start_ends[['trans_id','time','action']].groupby('trans_id').apply(grouper)[['time','count']].reset_index() \n",
    "result['trans_bins_id'] = result['trans_id'] + '_' + result['bins']\n",
    "bad_filt = result['time']==99\n",
    "bad_trans_bins = result[bad_filt]['trans_bins_id'].unique()\n",
    "#result = result[~bad_filt]\n",
    "result[['meter_id','day']] = result['trans_id'].str.split('_', expand=True)\n",
    "result['day'] = result['day'].astype(int)\n",
    "result = result.sort_values(['meter_id','day']).reset_index(drop=True)\n",
    "# got counts\n",
    "print('got observed')\n",
    "print(len(bad_trans_bins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413bd5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "def grouper(row, cut_off_time=9):\n",
    "    hours_actions = row[['time','action']].values.tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = counter + 1\n",
    "    if float(counter/10000).is_integer():\n",
    "        print(counter)\n",
    "\n",
    "    while hours_actions[0][1] == 'interval':\n",
    "        hours_actions.pop(0)\n",
    "\n",
    "    while hours_actions[-1][1] == 'interval':\n",
    "        hours_actions.pop(-1)\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action != 'interval')and(action==past_action):\n",
    "            if action == 'start':\n",
    "                pass\n",
    "            elif action == 'end':\n",
    "                keep.pop()\n",
    "                past_hour = hour\n",
    "                past_action = action\n",
    "                keep.append([hour, action])\n",
    "        elif action!=past_action:\n",
    "            # if action == 'end':\n",
    "            #     if (hour == 18)or(hour == 18.0):\n",
    "            #         hour = 17.99999\n",
    "            #     elif (hour == 12)or(hour == 12.0):\n",
    "            #         hour = 11.99999\n",
    "            #     elif (hour == 15)or(hour == 15.0):\n",
    "            #         hour = 14.99999\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action == 'interval'):\n",
    "            if(past_action == 'start'):\n",
    "                correct_end = hour-.00001\n",
    "                # if (hour == 18)or(hour == 18.0):\n",
    "                #     correct_end = 17.99999\n",
    "                # if (hour == 12)or(hour == 12.0):\n",
    "                #     correct_end = 11.99999\n",
    "                keep.append([correct_end,'end'])\n",
    "                keep.append([hour,'start'])\n",
    "                past_action = 'start'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "            \n",
    "    hours_actions = keep\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if action==past_action:\n",
    "            pass\n",
    "        elif action!=past_action:\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    # hours_actions_df = pd.DataFrame(keep, columns=['time','action'])\n",
    "    return pd.DataFrame(keep, columns=['time','action'])\n",
    "\n",
    "#trans_day_actions = hours_actions_df.map_partitions(grouper, meta={'time': 'int64', 'action': 'str'})\n",
    "trans_day_actions = trans_day_actions.groupby('trans_id')[['time','action']].apply(grouper, meta={'time': 'int64', 'action': 'str'})\n",
    "trans_day_actions = trans_day_actions.persist()\n",
    "\n",
    "print('after function')\n",
    "\n",
    "# path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_trans_day_clean_q1.csv'\n",
    "# trans_day_actions.to_csv(path)\n",
    "saved = trans_day_actions.to_csv(\"C:/Users/nelms/Documents/Penn/MUSA-508/MUSA508_FINAL_SFPARK/csv_counts_trans/*\", compute=False)\n",
    "_, l = dask.compute(saved, trans_day_actions.size)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #############\n",
    "\n",
    "# unique_list = list(hours_actions_df.index.unique().compute())\n",
    "# hours_actions_df = hours_actions_df.repartition(divisions=sorted(unique_list + [unique_list[-1]]))\n",
    "# print(trans_day_actions.npartitions)\n",
    "\n",
    "#################\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def grouper(row, cut_off_time=9):\n",
    "    hours_actions = row[['time','action']].values.tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = counter + 1\n",
    "    if float(counter/10000).is_integer():\n",
    "        print(counter)\n",
    "\n",
    "    while hours_actions[0][1] == 'interval':\n",
    "        hours_actions.pop(0)\n",
    "\n",
    "    while hours_actions[-1][1] == 'interval':\n",
    "        hours_actions.pop(-1)\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action != 'interval')and(action==past_action):\n",
    "            if action == 'start':\n",
    "                pass\n",
    "            elif action == 'end':\n",
    "                keep.pop()\n",
    "                past_hour = hour\n",
    "                past_action = action\n",
    "                keep.append([hour, action])\n",
    "        elif action!=past_action:\n",
    "            # if action == 'end':\n",
    "            #     if (hour == 18)or(hour == 18.0):\n",
    "            #         hour = 17.99999\n",
    "            #     elif (hour == 12)or(hour == 12.0):\n",
    "            #         hour = 11.99999\n",
    "            #     elif (hour == 15)or(hour == 15.0):\n",
    "            #         hour = 14.99999\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    hours_actions = keep\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if (action == 'interval'):\n",
    "            if(past_action == 'start'):\n",
    "                correct_end = hour-.00001\n",
    "                # if (hour == 18)or(hour == 18.0):\n",
    "                #     correct_end = 17.99999\n",
    "                # if (hour == 12)or(hour == 12.0):\n",
    "                #     correct_end = 11.99999\n",
    "                keep.append([correct_end,'end'])\n",
    "                keep.append([hour,'start'])\n",
    "                past_action = 'start'\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "            \n",
    "    hours_actions = keep\n",
    "    past_action = ''\n",
    "    keep = []\n",
    "    for hour, action in hours_actions:\n",
    "        if action==past_action:\n",
    "            pass\n",
    "        elif action!=past_action:\n",
    "            past_hour = hour\n",
    "            past_action = action\n",
    "            keep.append([hour, action])\n",
    "    #start_count = len([act for hr,act in keep if act=='start'])\n",
    "\n",
    "    # hours_actions_df = pd.DataFrame(keep, columns=['time','action'])\n",
    "    return pd.DataFrame(keep, columns=['time','action'])\n",
    "\n",
    "#trans_day_actions = hours_actions_df.map_partitions(grouper, meta={'time': 'int64', 'action': 'str'})\n",
    "trans_day_actions = trans_day_actions.groupby('trans_id')[['time','action']].apply(grouper, meta={'time': 'int64', 'action': 'str'})\n",
    "trans_day_actions = trans_day_actions.persist()\n",
    "\n",
    "print('after function')\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\parquet'\n",
    "trans_day_actions.to_parquet(path)\n",
    "print('exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_day_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_trans_day_clean.parquet'\n",
    "trans_day_actions = dd.read_parquet(path).set_index('trans_id').persist()\n",
    "\n",
    "#############\n",
    "\n",
    "cut_off_time = 9\n",
    "trans_day_actions = trans_day_actions[trans_day_actions['time']>=cut_off_time].drop_duplicates()\n",
    "trans_day_actions = trans_day_actions.persist()\n",
    "\n",
    "trans_day_actions['bins'] = pd.cut(\n",
    "            trans_day_actions['time'], \n",
    "            bins, \n",
    "            labels=labels, \n",
    "            right=False, include_lowest=True\n",
    "            ).astype(str)\n",
    "trans_day_actions = trans_day_actions[trans_day_actions['bins'].isin(good_bins)]\n",
    "trans_day_actions['block_day_bins'] = trans_day_actions['trans_id'] + '_' + trans_day_actions['bins']\n",
    "trans_day_actions = trans_day_actions[['block_day_bins', 'time']].set_index('block_day_bins')\n",
    "trans_day_actions = trans_day_actions.persist()\n",
    "\n",
    "#####\n",
    "\n",
    "unique_list = list(trans_day_actions.index.unique().compute())\n",
    "trans_day_actions = trans_day_actions.repartition(divisions=sorted(unique_list + [unique_list[-1]]))\n",
    "print(trans_day_actions.npartitions)\n",
    "\n",
    "#############\n",
    "\n",
    "counter = 0\n",
    "cols = ['time'] #,'count']\n",
    "def get_times(row):\n",
    "    #start_ends = row[['time', 'action']].values.tolist()\n",
    "\n",
    "    global counter\n",
    "    counter = counter + 1\n",
    "    if float(counter/100000).is_integer():\n",
    "        print(counter)\n",
    "\n",
    "    try:\n",
    "        start_ends = row[['time']].values.tolist()\n",
    "        start_ends = np.reshape(start_ends, (round(len(start_ends)/2), 2))\n",
    "\n",
    "        start_ends = [round_down(end-start,3) for start,end in start_ends]\n",
    "        return pd.Series((sum(start_ends), len(start_ends)), index=cols)\n",
    "\n",
    "    except:\n",
    "        #print(row[['time', 'action']].values.tolist())\n",
    "        return pd.Series((99, 99), index=cols)\n",
    "    #group_hours_actions_df = hours_actions_df.groupby(['bins', 'action'])['time'].apply(list) #.count()\n",
    "\n",
    "trans_day_actions = trans_day_actions.map_partitions(get_times, meta={'time': 'int64', 'action': 'str'})\n",
    "#trans_day_actions = trans_day_actions.groupby('bins').apply(get_times)\n",
    "\n",
    "#####\n",
    "\n",
    "path = r'C:\\Users\\nelms\\Documents\\Penn\\MUSA-508\\MUSA508_FINAL_SFPARK\\meter_trans_count.parquet'\n",
    "trans_day_actions.to_parquet(path, engine='pyarrow')\n",
    "print('exported')\n",
    "\n",
    "\n",
    "# result['trans_bins_id'] = result['trans_id'] + '_' + result['bins']\n",
    "# bad_filt = result['time']==99\n",
    "# bad_trans_bins = result[bad_filt]['trans_bins_id'].unique()\n",
    "# #result = result[~bad_filt]\n",
    "# result[['meter_id','day']] = result['trans_id'].str.split('_', expand=True)\n",
    "# result['day'] = result['day'].astype(int)\n",
    "# result = result.sort_values(['meter_id','day']).reset_index(drop=True)\n",
    "# # got counts\n",
    "# print('got observed')\n",
    "# print(len(bad_trans_bins))\n",
    "\n",
    "# 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_cols = ['block_day_bins','time','count']\n",
    "regs['poss_time'] = 3\n",
    "regs_group = regs[group_cols+['poss_time']].groupby('block_day_bins').agg(\n",
    "    transactions={'count':'sum'}, \n",
    "    occ_hours={'time':'sum'}, \n",
    "    all_hours={'poss_time':'sum'}\n",
    "    )\n",
    "regs_group['occupancy'] = regs_group['occ_hours'] / regs_group['all_hours']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
